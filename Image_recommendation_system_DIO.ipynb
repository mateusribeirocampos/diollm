{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUh/D0zJgK/wROH35SEZDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateusribeirocampos/diollm/blob/main/Image_recommendation_system_DIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de recomandação por imagens\n",
        "\n",
        "Projeto desenvolvido para o desafio da DIO sobre recomenadação por imagens. O modelo foi construído a partir do código de [exemplo](https://colab.research.google.com/github/sparsh-ai/rec-tutorials/blob/master/_notebooks/2021-04-27-image-similarity-recommendations.ipynb). O modelo utilizado foi [BiT collection]('https://tfhub.dev/google/bit/m-r50x1/1') da versão 1, que é mais leve que o modelo do exemplo."
      ],
      "metadata": {
        "id": "id-r6HHJ57Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "9CDk5I8a52z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação da ativação da GPU"
      ],
      "metadata": {
        "id": "0KsRVSU083xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "LFG8Y3a9827K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCPGArGr5w2A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import keras\n",
        "import itertools\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from shutil import move\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "xsquEjns54fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexão com API kaggle\n",
        "\n",
        "Identificação do usuário via API kaggle foi carregada para fazer o download do dataset em zip"
      ],
      "metadata": {
        "id": "EOAVOusk7CNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/kaggle.json', 'r') as file:\n",
        "    kaggle_creds = json.load(file)\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_creds['username']\n",
        "os.environ['KAGGLE_KEY'] = kaggle_creds['key']\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()"
      ],
      "metadata": {
        "id": "eBzPgIyK56Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
        "!unzip fashion-product-images-small.zip"
      ],
      "metadata": {
        "id": "Hv9HpCSv7BX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estrutura do dataset\n",
        "\n",
        "O diretório Fashion_data e as imagens foram criados e as imagens foram distribuídas em categorias dentro do Fashion_data"
      ],
      "metadata": {
        "id": "NOmu5Vh37bcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/Fashion_data')\n",
        "os.chdir('/content/Fashion_data')\n",
        "\n",
        "df = pd.read_csv('/content/styles.csv', usecols=['id','masterCategory']).reset_index()\n",
        "df['id'] = df['id'].astype('str')\n",
        "\n",
        "all_images = os.listdir('/content/images/')\n",
        "co = 0\n",
        "os.mkdir('/content/Fashion_data/categories')\n",
        "for image in tqdm(all_images):\n",
        "    category = df[df['id'] == image.split('.')[0]]['masterCategory']\n",
        "    category = str(list(category)[0])\n",
        "    if not os.path.exists(os.path.join('/content/Fashion_data/categories', category)):\n",
        "        os.mkdir(os.path.join('/content/Fashion_data/categories', category))\n",
        "    path_from = os.path.join('/content/images', image)\n",
        "    path_to = os.path.join('/content/Fashion_data/categories', category, image)\n",
        "    move(path_from, path_to)\n",
        "    co += 1\n",
        "print('Moved {} images.'.format(co))"
      ],
      "metadata": {
        "id": "Q_QGDOGw7bAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação das categorias e distribuição em gráfico"
      ],
      "metadata": {
        "id": "e8-I0ix575_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/styles.csv', on_bad_lines='skip')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PwJ98lse75Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15,5))\n",
        "sns.countplot(x='masterCategory',data=df)"
      ],
      "metadata": {
        "id": "Xp9Mslmp8FCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versão do Tensorflow e Tensorflow-hub\n",
        "\n",
        "As versões Tensorflow 2.13.0 e Tensorflow-hub 0.14.0 foram utilizadas para rodar o modelo."
      ],
      "metadata": {
        "id": "G5i_VHeP8Kf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13.0 tensorflow-hub==0.14.0"
      ],
      "metadata": {
        "id": "9NP5Qx_L8J5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)"
      ],
      "metadata": {
        "id": "yFrXH-QV9T5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "id": "ALWsbRGj9XJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload do modelo"
      ],
      "metadata": {
        "id": "DFfDchQw9y6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODULE_HANDLE = 'https://tfhub.dev/google/bit/m-r50x1/1'\n",
        "module = hub.load(MODULE_HANDLE)\n",
        "print(\"Módulo carregado com sucesso:\", module)"
      ],
      "metadata": {
        "id": "oaVPzCxq9cKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/Fashion_data/categories'"
      ],
      "metadata": {
        "id": "ntIMmP659_Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratamento das imagens para o modelo\n",
        "\n",
        "Dimensionamento dos valores de pixel, divisão dos dados em conjuntos de treinamento e validação e, opcionalmente, aplicação de aumentos às imagens de treinamento. Os objetos train_generator e valid_generator são iteradores que fornecerão lotes de imagens para seu modelo durante o treinamento e a avaliação, respectivamente."
      ],
      "metadata": {
        "id": "CJwqm_9I-RpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                   interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ],
      "metadata": {
        "id": "H4Dg_lYO-Asq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração do modelo de deep learning\n",
        "\n",
        "Configuração do modelo de Deep Learning para classificação de imagens usando um modelo pré-treinado [BiT collection]('https://tfhub.dev/google/bit/m-r50x1/1'). Personalização do modelo com adição das camadas dropout e densas, aplicada a regularização para evitar overfitting e exibe um resumo da arquitetura com model.summary()."
      ],
      "metadata": {
        "id": "LxKxVfcx-qmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=False),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(N_FEATURES,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "s2laX-hY-pw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do optmizer e perda\n",
        "\n",
        "Configuração dos componentes principais para treinar o modelo. Definição de como o modelo aprenderá (otimizador), o que ele pretende minimizar (função de perda) e como seu desempenho será avaliado (métricas). O cronograma de taxa de aprendizado é adicionado para ajustar dinamicamente a taxa de aprendizado durante o treinamento para melhor convergência."
      ],
      "metadata": {
        "id": "gprSABH3_mib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01 * BATCH_SIZE / 512\n",
        "SCHEDULE_LENGTH = 100\n",
        "SCHEDULE_BOUNDARIES = [200]\n",
        "\n",
        "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
        "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES,\n",
        "                                                                   values=[lr, lr*0.1])\n",
        "optimizer = tf.keras.optimizers.AdamW(learning_rate=3e-4, weight_decay=1e-4)\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "q79JRc7g_lw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variável checkpoint\n",
        "\n",
        "A variável checkpoint irá salvar o melhor modelo em best_model.keras com seu mair valor de treinamento."
      ],
      "metadata": {
        "id": "7eSOSV3fBuYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    filepath='best_model.keras',\n",
        "    monitor='val_acc',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "tRzqbZedBRIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do modelo deep learning\n",
        "\n",
        "Treinamento do modelo para duas épocas usando os dados de treinamento do train_generator, que será avaliado seu desempenho após cada época com os dados de validação do valid_generator. Os parâmetros steps_per_epoch e validation_steps controlam quantos lotes são usados ​​para treinamento e validação dentro de cada época, respectivamente. O histórico de treinamento (métricas) é salvo na variável history."
      ],
      "metadata": {
        "id": "JiKZ9WrwAh4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=2, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=[checkpoint],\n",
        "    validation_steps=validation_steps).history"
      ],
      "metadata": {
        "id": "oeUBp1VoAQlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gráfico do período de aprendizado do modelo"
      ],
      "metadata": {
        "id": "Vw-YjOVwCVzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(history[\"loss\"])\n",
        "plt.plot(history[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(history[\"accuracy\"])\n",
        "plt.plot(history[\"val_accuracy\"])"
      ],
      "metadata": {
        "id": "Wr9kWnhmCcMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvamento do modelo e extrator no google drive\n",
        "\n",
        "Modelo treinado e seu extrator de recursos armazenados com segurança no Google Drive para uso futuro."
      ],
      "metadata": {
        "id": "SsjWPqOcClnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/gdrive/MyDrive/ImgSim/'):\n",
        "    os.mkdir('/content/gdrive/MyDrive/ImgSim/')\n",
        "\n",
        "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
        "feature_extractor.save('/content/gdrive/MyDrive/ImgSim/bit_feature_extractor', save_format='tf')\n",
        "\n",
        "saved_model_path = '/content/gdrive/MyDrive/ImgSim/bit_model'\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "metadata": {
        "id": "LghV0kJTCfTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vetorização das imagens\n",
        "\n",
        "O vetor de características de cada imagem será salvo como uma matriz em um diretório. Após o processamento, salvaremos esses embeddings para uso posterior."
      ],
      "metadata": {
        "id": "q87kEOBQC8iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_paths = []\n",
        "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
        "  img_paths.append(path)\n",
        "np.random.shuffle(img_paths)"
      ],
      "metadata": {
        "id": "NILZdFl7C5A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSFER_LEARNING_FLAG = 1\n",
        "if TRANSFER_LEARNING_FLAG:\n",
        "  module = tf.keras.models.load_model('/content/gdrive/MyDrive/ImgSim/bit_feature_extractor')\n",
        "else:\n",
        "  module_handle = \"https://tfhub.dev/google/bit/m-r50x1/1/ilsvrc2012_classification/1\"\n",
        "  module = hub.load(module_handle)"
      ],
      "metadata": {
        "id": "JduzyEwdDWSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgvec_path = '/content/img_vectors/'\n",
        "Path(imgvec_path).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "4SZU5as0Da-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metadados e Indexação\n",
        "\n",
        "Será atribuido um id exclusivo a cada imagem e será criado dicionários para localizar informações dessa imagem: 1) Id da imagem para o dicionário de nome da imagem, 2) Id da imagem para o dicionário de vetor de recurso da imagem e 3) (opcional) Id da imagem para o dicionário de id do produto de metadados. Também criaremos um id da imagem para a indexação do vetor de recurso da imagem. Então, salvaremos esses dicionários e objetos de índice para uso posterior."
      ],
      "metadata": {
        "id": "CtXD8Y9cDeHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "!pip install -q annoy\n",
        "import json\n",
        "from annoy import AnnoyIndex\n",
        "from scipy import spatial\n",
        "import pickle\n",
        "from IPython.display import Image as dispImage"
      ],
      "metadata": {
        "id": "pty3cX3NDdZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imagem para teste do dataset"
      ],
      "metadata": {
        "id": "V-GzeNglEJtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = '/content/Fashion_data/categories/Accessories/1941.jpg'\n",
        "dispImage(test_img)"
      ],
      "metadata": {
        "id": "cBjwTCurDxxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verifica se o produto está no dataset\n",
        "\n",
        "A função match_id recebe um nome de arquivo (fname) como entrada. Ela procura um produto no DataFrame styles cujo ID corresponde ao nome do arquivo. Se encontrar uma correspondência, ela retorna o índice desse produto no DataFrame. Esse índice pode então ser usado para acessar outras informações sobre o produto, como sua categoria, descrição, etc., do DataFrame."
      ],
      "metadata": {
        "id": "oWWAJBwtESW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_id(fname):\n",
        "  return styles.index[styles.id==fname].values[0]"
      ],
      "metadata": {
        "id": "iRIM1qN7DzqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração das estruturas de dados necessárias para um sistema de busca de similaridade de imagem usando a biblioteca Annoy.\n",
        "\n",
        "Estruturas de dados: Três dicionários são criados para armazenar o mapeamento entre índices de arquivo de imagem, nomes de arquivo, vetores de recursos e (opcionalmente) IDs de produto. Esses dicionários serão preenchidos posteriormente para recuperar informações de imagem de forma eficiente.\n",
        "\n",
        "Configuração Annoy: Parâmetros-chave para o índice Annoy são definidos, incluindo a dimensionalidade dos vetores de recursos (dims), o número desejado de vizinhos mais próximos (n_nearest_neighbors) e o número de árvores no índice (árvores). Esses parâmetros influenciam a precisão e o desempenho da busca de similaridade.\n",
        "\n",
        "Leitura de arquivo: O código identifica e lê os caminhos de todos os arquivos que armazenam vetores de recursos de imagem, que serão usados ​​para construir o índice Annoy.\n",
        "\n",
        "Inicialização do índice: Um índice Annoy é inicializado com a dimensionalidade especificada e a métrica de distância ('angular'), preparando-o para armazenar e buscar vetores de imagem semelhantes."
      ],
      "metadata": {
        "id": "Gtm2qi9dExLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_index_to_file_name = {}\n",
        "file_index_to_file_vector = {}\n",
        "file_index_to_product_id = {}\n",
        "\n",
        "dims = 256\n",
        "n_nearest_neighbors = 20\n",
        "trees = 10000\n",
        "\n",
        "allfiles = glob.glob('/content/img_vectors/*.npz')\n",
        "\n",
        "t = AnnoyIndex(dims, metric='angular')"
      ],
      "metadata": {
        "id": "KaNyEZxwD2Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação dos dados para pesquisa de similaridade de imagem\n",
        "\n",
        "Carregamento dos vetores de recursos de arquivos, criação dos dicionários para mapear entre IDs de imagem, nomes, vetores e IDs de produtos, e, o mais importante, criação o índice Annoy para pesquisas rápidas de similaridade."
      ],
      "metadata": {
        "id": "Gj-d26_CFgzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for findex, fname in tqdm(enumerate(allfiles)):\n",
        "  file_vector = np.loadtxt(fname)\n",
        "  file_name = os.path.basename(fname).split('.')[0]\n",
        "  file_index_to_file_name[findex] = file_name\n",
        "  file_index_to_file_vector[findex] = file_vector\n",
        "  try:\n",
        "    file_index_to_product_id[findex] = match_id(file_name)\n",
        "  except IndexError:\n",
        "    pass\n",
        "  t.add_item(findex, file_vector)"
      ],
      "metadata": {
        "id": "Lp3AQI8xD4Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contrução do indexes com Annoy"
      ],
      "metadata": {
        "id": "fQoBQ6ffFzmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.build(trees)\n",
        "t.save('t.ann')"
      ],
      "metadata": {
        "id": "gL2IlmCuD5dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/gdrive/MyDrive/ImgSim/'"
      ],
      "metadata": {
        "id": "aBX_DQyRD61a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação do sistema de mapeamento de imagens por similaridade"
      ],
      "metadata": {
        "id": "5lkqN1YCGARk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.save(file_path+'indexer.ann')\n",
        "pickle.dump(file_index_to_file_name, open(file_path+\"file_index_to_file_name.p\", \"wb\"))\n",
        "pickle.dump(file_index_to_file_vector, open(file_path+\"file_index_to_file_vector.p\", \"wb\"))\n",
        "pickle.dump(file_index_to_product_id, open(file_path+\"file_index_to_product_id.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "wjXf__dKFvLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local de teste\n",
        "\n",
        "Será carregada uma imagem aleatória e será encontrada as K imagens mais semelhantes."
      ],
      "metadata": {
        "id": "7TB7und9GVe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "lNAKVyz7GT88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento da imagem aleatória para teste\n",
        "\n",
        "a imagem de teste para baixar da web será convertida em um vetor de características usando um codificador de imagem e redimensionará a imagem para exibição, preparando-a para a pesquisa de similaridade de imagens."
      ],
      "metadata": {
        "id": "walP_qHkGs0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_addr = 'https://images-na.ssl-images-amazon.com/images/I/81%2Bd6eSA0eL._UL1500_.jpg'\n",
        "\n",
        "!wget -q -O img.jpg $img_addr\n",
        "test_img = 'img.jpg'\n",
        "topK = 4\n",
        "\n",
        "test_vec = np.squeeze(module(load_img(test_img)))\n",
        "\n",
        "basewidth = 224\n",
        "img = Image.open(test_img)\n",
        "wpercent = (basewidth/float(img.size[0]))\n",
        "hsize = int((float(img.size[1])*float(wpercent)))\n",
        "img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
        "img"
      ],
      "metadata": {
        "id": "3byC_l_3D_rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado\n",
        "\n",
        "Criação de um dicionário da pesquisa de imagem, será encontrada as imagens semelhantes usando o índice Annoy e, em seguida, serão exibidas essas imagens semelhantes junto com suas informações de produto em uma figura Matplotlib."
      ],
      "metadata": {
        "id": "F0fKDq6GHlUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_dict = {}\n",
        "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
        "  path_dict[path.name] = path\n",
        "\n",
        "nns = t.get_nns_by_vector(test_vec, n=topK)\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(topK):\n",
        "  x = file_index_to_file_name[nns[i]]\n",
        "  x = path_dict[x+'.jpg']\n",
        "  y = file_index_to_product_id[nns[i]]\n",
        "  title = '\\n'.join([str(j) for j in list(styles.loc[y].values[-5:])])\n",
        "  plt.subplot(1, topK, i+1)\n",
        "  plt.title(title)\n",
        "  plt.imshow(mpimg.imread(x))\n",
        "  plt.axis('off')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "3WheUg1rEB6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}