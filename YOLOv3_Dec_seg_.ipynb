{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateusribeirocampos/diollm/blob/main/YOLOv3_Dec_seg_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m84GVjNMVIbX",
        "outputId": "2aa84ca1-4004-4f2b-d7b3-97bd71a46419"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do diretório darknet para o modelo yolo a partir do repositório de Alexey AB."
      ],
      "metadata": {
        "id": "SoUkKWTHHhjR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0obWMEJhTlhv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "%cd darknet\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!make clean && make"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação da pacote lipopencv-dv e tree\n",
        "\n",
        " It's the development version of OpenCV (Open Source Computer Vision Library), a popular library used for computer vision tasks (like image processing, object detection, etc.). The development version includes header files and libraries needed to build applications that use OpenCV.\n",
        "\n",
        " o pacote tree facilita a visualização da estrutura do projeto"
      ],
      "metadata": {
        "id": "NtTGw8w5HvWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libopencv-dev\n",
        "!sudo apt-get install tree"
      ],
      "metadata": {
        "id": "kE_VhxQAzch7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação dos arquivos\n",
        "\n",
        "Os arquivos vão receber as configurações e os database para o treino, validação e testes."
      ],
      "metadata": {
        "id": "g_EoqEPuYM5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/backup\n",
        "!mkdir -p /content/coco/images"
      ],
      "metadata": {
        "id": "OBf3tNp9V3C3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fazer o download\n",
        "\n",
        "Aqui é feito o download do database todos compactados"
      ],
      "metadata": {
        "id": "-hq2N39XYd3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar val2017 (1GB)\n",
        "!wget -c http://images.cocodataset.org/zips/val2017.zip -P /content/coco/images\n",
        "\n",
        "# Baixar test2017\n",
        "!wget -c http://images.cocodataset.org/zips/test2017.zip -P /content/coco/images\n",
        "\n",
        "# Baixar imagens de treino (18GB)\n",
        "!wget -c http://images.cocodataset.org/zips/train2017.zip -P /content/coco/images"
      ],
      "metadata": {
        "id": "1LU_Obqcb2y0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descompactação do database"
      ],
      "metadata": {
        "id": "zVoAhB3VYtIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/coco/annotations\n",
        "\n",
        "# Baixar anotações (train + val)\n",
        "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P /content/coco/annotations"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CgxsQ6f4id4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/coco/annotations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U54ObAeBkCoi",
        "outputId": "7b8afbd8-46a8-46ad-d522-83174649e885"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations_trainval2017.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompactar validações\n",
        "!unzip /content/coco/images/val2017.zip -d /content/coco/images\n",
        "!rm /content/coco/images/val2017.zip\n",
        "\n",
        "# Descompactar imagens de testes\n",
        "!unzip /content/coco/images/test2017.zip -d /content/coco/images\n",
        "!rm /content/coco/images/test2017.zip"
      ],
      "metadata": {
        "id": "PEMYHLIrmTvb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompactar imagens\n",
        "!unzip /content/coco/images/train2017.zip -d /content/coco/images\n",
        "!rm /content/coco/images/train2017.zip\n",
        "\n",
        "# Descompactar anotações de treino e validações\n",
        "!unzip /content/coco/annotations/annotations_trainval2017.zip -d /content/coco/annotations\n",
        "!rm /content/coco/annotations/annotations_trainval2017.zip"
      ],
      "metadata": {
        "id": "HXB5jQcTaxHu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos arquivos annotations"
      ],
      "metadata": {
        "id": "ZBDkSfkhYy6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/coco/annotations/"
      ],
      "metadata": {
        "id": "1s4GTMRmgCIS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mova todos os JSONs para /content/coco/annotations/\n",
        "!mv /content/coco/annotations/annotations/*.json /content/coco/annotations/\n",
        "!rm -rf /content/coco/annotations/annotations"
      ],
      "metadata": {
        "id": "4OeFes-QmJYX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/coco/annotations/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3w5PV6WmLVy",
        "outputId": "b236e5fa-002d-49f8-e838-438cf446b920"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "captions_train2017.json  instances_train2017.json  person_keypoints_train2017.json\n",
            "captions_val2017.json\t instances_val2017.json    person_keypoints_val2017.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estrutura dos diretórios"
      ],
      "metadata": {
        "id": "yWgsLBAdY412"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -d /content/coco/"
      ],
      "metadata": {
        "id": "kb8ZwgnzorK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1874294-aa12-4dcc-8475-e0de1834ff4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/coco/\u001b[0m\n",
            "├── \u001b[01;34mannotations\u001b[0m\n",
            "└── \u001b[01;34mimages\u001b[0m\n",
            "    ├── \u001b[01;34mtest2017\u001b[0m\n",
            "    ├── \u001b[01;34mtrain2017\u001b[0m\n",
            "    └── \u001b[01;34mval2017\u001b[0m\n",
            "\n",
            "5 directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -d /content/coco/images/"
      ],
      "metadata": {
        "id": "kHTC3e5YuWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8c6174-c92a-40c2-9a12-8f8170cb5982"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/coco/images/\u001b[0m\n",
            "├── \u001b[01;34mtest2017\u001b[0m\n",
            "├── \u001b[01;34mtrain2017\u001b[0m\n",
            "└── \u001b[01;34mval2017\u001b[0m\n",
            "\n",
            "3 directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função de criação dos arquvivos para treino e validação."
      ],
      "metadata": {
        "id": "nbCAdLeiY-pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "def setup_coco_directories(base_dir: str, splits: list):\n",
        "    \"\"\"Cria a estrutura de diretórios para o dataset filtrado\"\"\"\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "    for split in splits:\n",
        "        os.makedirs(os.path.join(base_dir, split, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(base_dir, split, 'labels'), exist_ok=True)\n",
        "\n",
        "def create_config_files(base_dir: str, categories: list):\n",
        "    \"\"\"Cria os arquivos de configuração obj.names e obj.data\"\"\"\n",
        "    # obj.names\n",
        "    with open(os.path.join(base_dir, 'obj.names'), 'w') as f:\n",
        "        f.write('\\n'.join(categories))\n",
        "\n",
        "    # obj.data (corrigido indentação)\n",
        "    config_content = f\"\"\"classes = {len(categories)}\n",
        "train = {os.path.join(base_dir, 'train.txt')}\n",
        "valid = {os.path.join(base_dir, 'val.txt')}\n",
        "names = {os.path.join(base_dir, 'obj.names')}\n",
        "backup = /content/backup\n",
        "\"\"\"\n",
        "    with open(os.path.join(base_dir, 'obj.data'), 'w') as f:\n",
        "        f.write(config_content)\n",
        "\n",
        "def generate_split_filelists(base_dir: str, splits: list):\n",
        "    \"\"\"Gera os arquivos train.txt e val.txt com caminhos absolutos\"\"\"\n",
        "    for split in splits:\n",
        "        if split == 'test': continue\n",
        "\n",
        "        img_dir = os.path.join(base_dir, split, 'images')\n",
        "        output_file = os.path.join(base_dir, f'{split}.txt')\n",
        "\n",
        "        # Verifica se o diretório de imagens existe\n",
        "        if not os.path.exists(img_dir):\n",
        "            raise FileNotFoundError(f\"Diretório não encontrado: {img_dir}\")\n",
        "\n",
        "        with open(output_file, 'w') as f:\n",
        "            for img_name in sorted(os.listdir(img_dir)):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    f.write(f\"{img_dir}/{img_name}\\n\")\n",
        "\n",
        "def process_coco_split(splits: list, categories: list, max_samples_per_split: int = None):\n",
        "    \"\"\"Processa splits do COCO convertendo para formato YOLO\"\"\"\n",
        "    base_dir = '/content/coco/filtered'\n",
        "\n",
        "    # 1. Criar estrutura de diretórios\n",
        "    setup_coco_directories(base_dir, splits)\n",
        "\n",
        "    # 2. Criar arquivos de configuração\n",
        "    create_config_files(base_dir, categories)\n",
        "\n",
        "    # 3. Processar cada split\n",
        "    for split in splits:\n",
        "        print(f\"\\nProcessando split: {split}\")\n",
        "        img_source_dir = f'/content/coco/images/{split}2017'\n",
        "        img_dest_dir = os.path.join(base_dir, split, 'images')\n",
        "\n",
        "        # Verificar origem das imagens\n",
        "        if not os.path.exists(img_source_dir):\n",
        "            raise FileNotFoundError(f\"Diretório de origem não encontrado: {img_source_dir}\")\n",
        "\n",
        "        # Processar imagens\n",
        "        if split == 'test':\n",
        "            images = [{'file_name': f} for f in os.listdir(img_source_dir)]\n",
        "        else:\n",
        "            coco = COCO(f'/content/coco/annotations/instances_{split}2017.json')\n",
        "            cat_ids = coco.getCatIds(catNms=categories)\n",
        "            img_ids = coco.getImgIds(catIds=cat_ids)\n",
        "            images = coco.loadImgs(img_ids[:max_samples_per_split] if max_samples_per_split else img_ids)\n",
        "\n",
        "        # Limitar amostras\n",
        "        if max_samples_per_split and split != 'test':\n",
        "            images = images[:max_samples_per_split]\n",
        "\n",
        "        # Copiar imagens\n",
        "        for img in images:\n",
        "            src = os.path.join(img_source_dir, img['file_name'])\n",
        "            dst = os.path.join(img_dest_dir, img['file_name'])\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "        # Processar anotações para train/val\n",
        "        if split != 'test':\n",
        "            ann_dest_dir = os.path.join(base_dir, split, 'labels')\n",
        "            os.makedirs(ann_dest_dir, exist_ok=True)\n",
        "\n",
        "            coco = COCO(f'/content/coco/annotations/instances_{split}2017.json')\n",
        "\n",
        "            for img in images:\n",
        "                ann_ids = coco.getAnnIds(imgIds=img['id'], catIds=cat_ids)\n",
        "                annotations = coco.loadAnns(ann_ids)\n",
        "\n",
        "                label_path = os.path.join(ann_dest_dir, img['file_name'].replace('.jpg', '.txt'))\n",
        "                with open(label_path, 'w') as f:\n",
        "                    for ann in annotations:\n",
        "                        x, y, w, h = ann['bbox']\n",
        "                        img_w, img_h = img['width'], img['height']\n",
        "\n",
        "                        # Conversão para formato YOLO\n",
        "                        cx = (x + w/2) / img_w\n",
        "                        cy = (y + h/2) / img_h\n",
        "                        nw = w / img_w\n",
        "                        nh = h / img_h\n",
        "\n",
        "                        class_id = categories.index(coco.loadCats(ann['category_id'])[0]['name'])\n",
        "                        f.write(f\"{class_id} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\\n\")\n",
        "\n",
        "    # 4. Gerar listas de imagens após processamento\n",
        "    generate_split_filelists(base_dir, splits)\n",
        "\n",
        "    # 5. Validar estrutura\n",
        "    print(\"\\nValidação final:\")\n",
        "    !tree {base_dir} -L 2\n",
        "    print(\"\\nExemplo de arquivo train.txt:\")\n",
        "    !head -n 2 {os.path.join(base_dir, 'train.txt')}\n",
        "\n",
        "# Execução\n",
        "process_coco_split(\n",
        "    splits=['train', 'val', 'test'],\n",
        "    categories=['boat', 'person'],\n",
        "    max_samples_per_split=500\n",
        ")"
      ],
      "metadata": {
        "id": "5KkwWlCNdKk_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos diretórios de treino e validação"
      ],
      "metadata": {
        "id": "esURIogweBx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifique se existem e contêm caminhos das imagens\n",
        "!ls /content/coco/filtered/train.txt /content/coco/filtered/val.txt\n",
        "\n",
        "# Exemplo do conteúdo de train.txt (primeiras 2 linhas)\n",
        "!head -n 2 /content/coco/filtered/train.txt"
      ],
      "metadata": {
        "id": "Od-tqcwkx0Gs",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/coco/filtered -L 2"
      ],
      "metadata": {
        "id": "zPF2dxzax4Yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d42735-0927-4869-9e24-c52260e969f3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/coco/filtered\u001b[0m\n",
            "├── \u001b[00mobj.data\u001b[0m\n",
            "├── \u001b[00mobj.names\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[01;34mimages\u001b[0m\n",
            "│   └── \u001b[01;34mlabels\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[01;34mimages\u001b[0m\n",
            "│   └── \u001b[01;34mlabels\u001b[0m\n",
            "├── \u001b[00mtrain.txt\u001b[0m\n",
            "├── \u001b[01;34mval\u001b[0m\n",
            "│   ├── \u001b[01;34mimages\u001b[0m\n",
            "│   └── \u001b[01;34mlabels\u001b[0m\n",
            "└── \u001b[00mval.txt\u001b[0m\n",
            "\n",
            "9 directories, 4 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação de Integridade"
      ],
      "metadata": {
        "id": "AZn-Nfw5eIIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_dataset(base_dir: str, splits: list):\n",
        "    \"\"\"Valida se número de imagens e labels corresponde\"\"\"\n",
        "    for split in splits:\n",
        "        img_dir = os.path.join(base_dir, split, 'images')\n",
        "        label_dir = os.path.join(base_dir, split, 'labels')\n",
        "\n",
        "        num_images = len(os.listdir(img_dir))\n",
        "        num_labels = len(os.listdir(label_dir)) if split != 'test' else print(\"OK\")\n",
        "\n",
        "        print(f\"{split}: {num_images} imagens, {num_labels} labels\")\n",
        "        if split != 'test' and num_images != num_labels:\n",
        "            raise ValueError(\"Inconsistência entre imagens e labels!\")"
      ],
      "metadata": {
        "id": "Lhr0hXuuYAEb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Controle de Versão dos Arquivos Gerados"
      ],
      "metadata": {
        "id": "D308fR_6ePyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset_version(base_dir: str):\n",
        "    \"\"\"Salva metadados da versão do dataset\"\"\"\n",
        "    version_info = {\n",
        "        'created_at': datetime.now().isoformat(),\n",
        "        'categories': ['boat', 'person'],\n",
        "        'splits': ['train', 'val', 'test'],\n",
        "        'num_samples': {split: len(os.listdir(os.path.join(base_dir, split, 'images')))\n",
        "                       for split in ['train', 'val', 'test']}\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(base_dir, 'version.json'), 'w') as f:\n",
        "        json.dump(version_info, f, indent=2)"
      ],
      "metadata": {
        "id": "eyDr4J-5YEuQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documentação"
      ],
      "metadata": {
        "id": "3TIfN1W0eTt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_documentation(base_dir: str):\n",
        "    \"\"\"Cria arquivo README com informações do dataset\"\"\"\n",
        "    readme_content = f\"\"\"# COCO Filtered Dataset\n",
        "\n",
        "    ## Categories\n",
        "    {', '.join(['boat', 'person'])}\n",
        "\n",
        "    ## Splits\n",
        "    {', '.join(['train', 'val', 'test'])}\n",
        "\n",
        "    ## Statistics\n",
        "    \"\"\"\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        num_images = len(os.listdir(os.path.join(base_dir, split, 'images')))\n",
        "        readme_content += f\"\\n- {split}: {num_images} images\"\n",
        "\n",
        "    with open(os.path.join(base_dir, 'README.md'), 'w') as f:\n",
        "        f.write(readme_content)"
      ],
      "metadata": {
        "id": "XoMftU-6YHUy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adição dos pesos para treino"
      ],
      "metadata": {
        "id": "ggyyvb7MeXdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "id": "WdkVSZXUiGNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704c04e7-bbed-49bb-bbb1-c117fdba3847"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-16 12:00:28--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  16.9MB/s    in 14s     \n",
            "\n",
            "2025-02-16 12:00:43 (16.8 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação do diretório onde os pesos foram salvos"
      ],
      "metadata": {
        "id": "2NO48XYGeZ4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!which yolov3.weights"
      ],
      "metadata": {
        "id": "C200_GyniY6O"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos nomes"
      ],
      "metadata": {
        "id": "hkaX4yUpehqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/coco/filtered/obj.names"
      ],
      "metadata": {
        "id": "8_zl8w5oxCTq",
        "outputId": "d89c36d8-a976-4cba-d679-def673a80f6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "boat\n",
            "person"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos dados"
      ],
      "metadata": {
        "id": "-RxO0BmAemBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/coco/filtered/obj.data"
      ],
      "metadata": {
        "id": "cYBVcPx2xk46",
        "outputId": "bdde2099-b89f-4b9f-e52e-41579c9130f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes = 2\n",
            "train = /content/coco/filtered/train.txt\n",
            "valid = /content/coco/filtered/val.txt\n",
            "names = /content/coco/filtered/obj.names\n",
            "backup = /content/backup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração dos arquvios para treino"
      ],
      "metadata": {
        "id": "R7o203YSepFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria cópia do cfg original\n",
        "!cp cfg/yolov3.cfg cfg/yolov3_custom.cfg\n",
        "\n",
        "# Aplica modificações\n",
        "!sed -i 's/batch=1/batch=64/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/subdivisions=1/subdivisions=16/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/max_batches = 500200/max_batches = 6000/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/classes=80/classes=2/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/filters=255/filters=21/' cfg/yolov3_custom.cfg"
      ],
      "metadata": {
        "id": "J6gD6lItiq-L"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução dos testes"
      ],
      "metadata": {
        "id": "MBvNWFjnet6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector train /content/coco/filtered/obj.data cfg/yolov3_custom.cfg yolov3.weights -dont_show -map"
      ],
      "metadata": {
        "id": "cG7Rr9mHwzUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/coco/filtered/train -L 2"
      ],
      "metadata": {
        "id": "Zn_gjiEA0FIN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu17DNat3P9i",
        "outputId": "bf79070e-e045-42b5-e609-8189cc63033f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 16 13:05:27 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p imgFromWebTest\n",
        "!wget -O imgFromWebTest/test_image.jpg https://img.freepik.com/free-photo/back-view-young-citizens-walking-street-with-phones_74855-4948.jpg?t=st=1739710472~exp=1739714072~hmac=592a6dc15dbb5e83e1469b1dadb5ba59c00f6b94c2410a15daffd3cf1b5397bf&w=1060/640/480"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ivKerCQuDfK",
        "outputId": "aa78a2bc-f12d-465d-a25f-ee71745806d9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-16 12:54:53--  https://img.freepik.com/free-photo/back-view-young-citizens-walking-street-with-phones_74855-4948.jpg?t=st=1739710472~exp=1739714072~hmac=592a6dc15dbb5e83e1469b1dadb5ba59c00f6b94c2410a15daffd3cf1b5397bf\n",
            "Resolving img.freepik.com (img.freepik.com)... 96.16.53.162, 96.16.53.137, 2a02:26f0:1180:19::212:790b, ...\n",
            "Connecting to img.freepik.com (img.freepik.com)|96.16.53.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87372 (85K) [image/jpeg]\n",
            "Saving to: ‘imgFromWebTest/test_image.jpg’\n",
            "\n",
            "\r          imgFromWe   0%[                    ]       0  --.-KB/s               \rimgFromWebTest/test 100%[===================>]  85.32K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-02-16 12:54:53 (1.28 MB/s) - ‘imgFromWebTest/test_image.jpg’ saved [87372/87372]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name \"test_image.jpg\" 2>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFd9L55WvG7Z",
        "outputId": "c1439ddf-a6f6-4076-9e1d-f0da0141d322"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet/imgFromWebTest/test_image.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh predictions.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-2_az9weug",
        "outputId": "a6414e34-2463-4ab8-a0ab-c85b59a44b3a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'predictions.jpg': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector test /content/coco/filtered/obj.data cfg/yolov3_custom.cfg /content/backup/yolov3_custom_final.weights /content/darknet/imgFromWebTest/test_image.jpg -dont_show"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SImmQZjywkAJ",
        "outputId": "1581c36c-f379-40e4-c7da-14d57ddd9cde"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CUDA-version: 12050 (12040)\n",
            " Warning: CUDA-version is higher than Driver-version! \n",
            ", cuDNN: 9.2.1, GPU count: 1  \n",
            " OpenCV version: 4.5.4\n",
            " 0 : compute_capability = 750, cudnn_half = 0, GPU: Tesla T4 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 Create CUDA-stream - 0 \n",
            " Create cudnn-handle 0 \n",
            "conv     32       3 x 3/ 1    416 x 416 x   3 ->  416 x 416 x  32 0.299 BF\n",
            "   1 conv     64       3 x 3/ 2    416 x 416 x  32 ->  208 x 208 x  64 1.595 BF\n",
            "   2 conv     32       1 x 1/ 1    208 x 208 x  64 ->  208 x 208 x  32 0.177 BF\n",
            "   3 conv     64       3 x 3/ 1    208 x 208 x  32 ->  208 x 208 x  64 1.595 BF\n",
            "   4 Shortcut Layer: 1,  wt = 0, wn = 0, outputs: 208 x 208 x  64 0.003 BF\n",
            "   5 conv    128       3 x 3/ 2    208 x 208 x  64 ->  104 x 104 x 128 1.595 BF\n",
            "   6 conv     64       1 x 1/ 1    104 x 104 x 128 ->  104 x 104 x  64 0.177 BF\n",
            "   7 conv    128       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x 128 1.595 BF\n",
            "   8 Shortcut Layer: 5,  wt = 0, wn = 0, outputs: 104 x 104 x 128 0.001 BF\n",
            "   9 conv     64       1 x 1/ 1    104 x 104 x 128 ->  104 x 104 x  64 0.177 BF\n",
            "  10 conv    128       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x 128 1.595 BF\n",
            "  11 Shortcut Layer: 8,  wt = 0, wn = 0, outputs: 104 x 104 x 128 0.001 BF\n",
            "  12 conv    256       3 x 3/ 2    104 x 104 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  13 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  14 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  15 Shortcut Layer: 12,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  16 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  17 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  18 Shortcut Layer: 15,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  19 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  20 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  21 Shortcut Layer: 18,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  22 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  23 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  24 Shortcut Layer: 21,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  25 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  26 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  27 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  28 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  29 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  30 Shortcut Layer: 27,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  31 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  32 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  33 Shortcut Layer: 30,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  34 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  35 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  36 Shortcut Layer: 33,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  37 conv    512       3 x 3/ 2     52 x  52 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  38 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  39 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  40 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  41 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  42 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  43 Shortcut Layer: 40,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  44 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  45 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  46 Shortcut Layer: 43,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  47 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  48 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  49 Shortcut Layer: 46,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  50 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  51 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  52 Shortcut Layer: 49,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  53 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  54 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  55 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  56 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  57 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  58 Shortcut Layer: 55,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  59 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  60 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  61 Shortcut Layer: 58,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  62 conv   1024       3 x 3/ 2     26 x  26 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  63 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  64 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  65 Shortcut Layer: 62,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  66 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  67 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  68 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  69 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  70 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  71 Shortcut Layer: 68,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  72 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  73 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  74 Shortcut Layer: 71,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  75 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  76 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  77 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  78 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  79 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  80 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  81 conv     21       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x  21 0.007 BF\n",
            "  82 yolo\n",
            "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "  83 route  79 \t\t                           ->   13 x  13 x 512 \n",
            "  84 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n",
            "  85 upsample                 2x    13 x  13 x 256 ->   26 x  26 x 256\n",
            "  86 route  85 61 \t                           ->   26 x  26 x 768 \n",
            "  87 conv    256       1 x 1/ 1     26 x  26 x 768 ->   26 x  26 x 256 0.266 BF\n",
            "  88 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  89 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  90 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  91 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  92 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  93 conv     21       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x  21 0.015 BF\n",
            "  94 yolo\n",
            "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "  95 route  91 \t\t                           ->   26 x  26 x 256 \n",
            "  96 conv    128       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 128 0.044 BF\n",
            "  97 upsample                 2x    26 x  26 x 128 ->   52 x  52 x 128\n",
            "  98 route  97 36 \t                           ->   52 x  52 x 384 \n",
            "  99 conv    128       1 x 1/ 1     52 x  52 x 384 ->   52 x  52 x 128 0.266 BF\n",
            " 100 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 101 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 102 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 103 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 104 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 105 conv     21       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x  21 0.029 BF\n",
            " 106 yolo\n",
            "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 65.312 \n",
            "avg_outputs = 516922 \n",
            " Allocate additional workspace_size = 52.44 MB \n",
            "Loading weights from /content/backup/yolov3_custom_final.weights...\n",
            " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
            "Done! Loaded 107 layers from weights-file \n",
            " Detection layer: 82 - type = 28 \n",
            " Detection layer: 94 - type = 28 \n",
            " Detection layer: 106 - type = 28 \n",
            "CUDA status Error: file: ./src/blas_kernels.cu: func: add_bias_gpu() line: 121\n",
            "\n",
            " CUDA Error: the provided PTX was compiled with an unsupported toolchain.\n",
            "Darknet error location: ./src/blas_kernels.cu, add_bias_gpu(), line #121\n",
            "CUDA Error: the provided PTX was compiled with an unsupported toolchain.: Success\n",
            "backtrace (13 entries)\n",
            "1/13: ./darknet(log_backtrace+0x38) [0x56f99b8591f8]\n",
            "2/13: ./darknet(error+0x3d) [0x56f99b8592dd]\n",
            "3/13: ./darknet(check_error+0xd0) [0x56f99b85bbd0]\n",
            "4/13: ./darknet(check_error_extended+0x7c) [0x56f99b85bcbc]\n",
            "5/13: ./darknet(forward_convolutional_layer_gpu+0x304) [0x56f99b934e64]\n",
            "6/13: ./darknet(forward_network_gpu+0xc1) [0x56f99b9493e1]\n",
            "7/13: ./darknet(network_predict_gpu+0x140) [0x56f99b94bc70]\n",
            "8/13: ./darknet(test_detector+0x33c) [0x56f99b8e63cc]\n",
            "9/13: ./darknet(run_detector+0x964) [0x56f99b8e7dc4]\n",
            "10/13: ./darknet(main+0x326) [0x56f99b818766]\n",
            "11/13: /lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x786f56bd4d90]\n",
            "12/13: /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x786f56bd4e40]\n",
            "13/13: ./darknet(_start+0x25) [0x56f99b81a9e5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/backup/yolov3_custom_final.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VvUYFrZ2Y6o",
        "outputId": "f7531ef4-14ef-432a-fa1b-8c0321c78b6a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 246326928 Feb 16 12:19 /content/backup/yolov3_custom_final.weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/darknet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3bGgnlCxBBQ",
        "outputId": "e07a7702-569a-4c1d-9f51-66e39779c57d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 242M\n",
            "drwxr-xr-x 5 root root 4.0K Feb 16 11:25 3rdparty\n",
            "drwxr-xr-x 2 root root 4.0K Feb 16 11:25 backup\n",
            "-rw-r--r-- 1 root root 6.7K Feb 16 12:19 bad.list\n",
            "drwxr-xr-x 3 root root 4.0K Feb 16 11:25 build\n",
            "-rwxr-xr-x 1 root root  44K Feb 16 11:25 build.ps1\n",
            "drwxr-xr-x 3 root root 4.0K Feb 16 12:01 cfg\n",
            "drwxr-xr-x 3 root root 4.0K Feb 16 11:25 cmake\n",
            "-rw-r--r-- 1 root root  30K Feb 16 11:25 CMakeLists.txt\n",
            "-rwxr-xr-x 1 root root 4.8M Feb 16 11:27 darknet\n",
            "-rw-r--r-- 1 root root 1.5K Feb 16 11:25 DarknetConfig.cmake.in\n",
            "-rw-r--r-- 1 root root 9.4K Feb 16 11:25 darknet_images.py\n",
            "-rw-r--r-- 1 root root  11K Feb 16 11:25 darknet.py\n",
            "-rw-r--r-- 1 root root 7.9K Feb 16 11:25 darknet_video.py\n",
            "drwxr-xr-x 3 root root 4.0K Feb 16 11:25 data\n",
            "-rw-r--r-- 1 root root  366 Feb 16 11:25 docker-compose.yml\n",
            "-rw-r--r-- 1 root root  774 Feb 16 11:25 Dockerfile.cpu\n",
            "-rw-r--r-- 1 root root  834 Feb 16 11:25 Dockerfile.gpu\n",
            "-rwxr-xr-x 1 root root  110 Feb 16 11:25 image_yolov3.sh\n",
            "-rwxr-xr-x 1 root root  110 Feb 16 11:25 image_yolov4.sh\n",
            "drwxr-xr-x 2 root root 4.0K Feb 16 12:28 imgFromWebTest\n",
            "drwxr-xr-x 2 root root 4.0K Feb 16 11:25 include\n",
            "-rwxr-xr-x 1 root root  345 Feb 16 11:25 json_mjpeg_streams.sh\n",
            "-rw-r--r-- 1 root root  515 Feb 16 11:25 LICENSE\n",
            "-rw-r--r-- 1 root root 6.5K Feb 16 11:25 Makefile\n",
            "-rwxr-xr-x 1 root root  159 Feb 16 11:25 net_cam_v3.sh\n",
            "-rwxr-xr-x 1 root root  159 Feb 16 11:25 net_cam_v4.sh\n",
            "drwxr-xr-x 2 root root 4.0K Feb 16 11:27 obj\n",
            "-rw-r--r-- 1 root root  712 Feb 16 11:25 package.xml\n",
            "-rw-r--r-- 1 root root  67K Feb 16 11:25 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Feb 16 11:25 results\n",
            "drwxr-xr-x 4 root root 4.0K Feb 16 11:25 scripts\n",
            "drwxr-xr-x 3 root root 4.0K Feb 16 11:25 src\n",
            "-rw-r--r-- 1 root root 2.1K Feb 16 11:25 vcpkg.json\n",
            "-rwxr-xr-x 1 root root  108 Feb 16 11:25 video_yolov3.sh\n",
            "-rwxr-xr-x 1 root root  108 Feb 16 11:25 video_yolov4.sh\n",
            "-rw-r--r-- 1 root root 237M Dec  7  2023 yolov3.weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image = cv2.imread('predictions.jpg')\n",
        "if image is None:\n",
        "    print(\"Erro: Imagem não encontrada ou corrompida.\")\n",
        "else:\n",
        "    image = cv2.imread('predictions.jpg')\n",
        "    plt.imshow(image)\n",
        "    print(\"Imagem carregada com sucesso.\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyLnLc74xM4N",
        "outputId": "bae9c322-246b-4f0d-a962-4433ae32b040"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro: Imagem não encontrada ou corrompida.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('predictions.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "h2FvNHuhuK0S",
        "outputId": "33ddfc48-a9b6-42ed-9224-8dcf8c05ade5"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-c04362ac86ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}