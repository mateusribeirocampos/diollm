{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyqMotooaFbuVbQ22UluZR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateusribeirocampos/diollm/blob/main/YOLOv3_Dec_seg_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m84GVjNMVIbX",
        "outputId": "e75ee105-de4b-42f7-cc22-ccb2de835057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do diretório darknet para o modelo yolo a partir do repositório de Alexey AB."
      ],
      "metadata": {
        "id": "SoUkKWTHHhjR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0obWMEJhTlhv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "%cd darknet\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!make clean && make"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação da pacote lipopencv-dv e tree\n",
        "\n",
        " It's the development version of OpenCV (Open Source Computer Vision Library), a popular library used for computer vision tasks (like image processing, object detection, etc.). The development version includes header files and libraries needed to build applications that use OpenCV.\n",
        "\n",
        " o pacote tree facilita a visualização da estrutura do projeto"
      ],
      "metadata": {
        "id": "NtTGw8w5HvWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libopencv-dev\n",
        "!sudo apt-get install tree"
      ],
      "metadata": {
        "id": "kE_VhxQAzch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação dos arquivos\n",
        "\n",
        "Os arquivos vão receber as configurações e os database para o treino, validação e testes."
      ],
      "metadata": {
        "id": "g_EoqEPuYM5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/backup\n",
        "!mkdir -p /content/coco/images\n",
        "!mkdir -p /content/coco/annotations"
      ],
      "metadata": {
        "id": "OBf3tNp9V3C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fazer o download\n",
        "\n",
        "Aqui é feito o download do database todos compactados"
      ],
      "metadata": {
        "id": "-hq2N39XYd3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar val2017 (1GB)\n",
        "!wget -c http://images.cocodataset.org/zips/val2017.zip -P /content/coco/images\n",
        "\n",
        "# Baixar test2017\n",
        "!wget -c http://images.cocodataset.org/zips/test2017.zip -P /content/coco/images\n",
        "\n",
        "# Baixar anotações (train + val)\n",
        "!wget -c http://images.cocodataset.org/annotations_trainval2017.zip -P /content/coco/annotations\n",
        "\n",
        "# Baixar imagens de treino (18GB)\n",
        "!wget -c http://images.cocodataset.org/zips/train2017.zip -P /content/coco/images"
      ],
      "metadata": {
        "id": "1LU_Obqcb2y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desconpactação do database"
      ],
      "metadata": {
        "id": "zVoAhB3VYtIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompactar validações\n",
        "!unzip /content/coco/images/val2017.zip -d /content/coco/images\n",
        "!rm /content/coco/images/val2017.zip\n",
        "\n",
        "# Descompactar imagens de testes\n",
        "!unzip /content/coco/images/test2017.zip -d /content/coco/images\n",
        "!rm /content/coco/images/test2017.zip"
      ],
      "metadata": {
        "id": "PEMYHLIrmTvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompactar imagens\n",
        "!unzip /content/coco/images/train2017.zip -d /content/coco/images\n",
        "!rm /content/coco/images/train2017.zip\n",
        "\n",
        "# Descompactar anotações de treino e validações\n",
        "!unzip /content/coco/annotations/annotations_trainval2017.zip -d /content/coco/annotations\n",
        "!rm /content/coco/annotations/annotations_trainval2017.zip"
      ],
      "metadata": {
        "id": "HXB5jQcTaxHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos arquivos annotations"
      ],
      "metadata": {
        "id": "ZBDkSfkhYy6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/coco/annotations/"
      ],
      "metadata": {
        "id": "1s4GTMRmgCIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estrutura dos diretórios"
      ],
      "metadata": {
        "id": "yWgsLBAdY412"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -d /content/coco/"
      ],
      "metadata": {
        "id": "kb8ZwgnzorK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -d /content/coco/images/"
      ],
      "metadata": {
        "id": "kHTC3e5YuWvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função de criação dos arquvivos para treino e validação."
      ],
      "metadata": {
        "id": "nbCAdLeiY-pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "def setup_coco_directories(base_dir: str, splits: list):\n",
        "    \"\"\"Cria a estrutura de diretórios para o dataset filtrado\"\"\"\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "    for split in splits:\n",
        "        os.makedirs(os.path.join(base_dir, split, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(base_dir, split, 'labels'), exist_ok=True)\n",
        "\n",
        "def create_config_files(base_dir: str, categories: list):\n",
        "    \"\"\"Cria os arquivos de configuração obj.names e obj.data\"\"\"\n",
        "    # obj.names\n",
        "    with open(os.path.join(base_dir, 'obj.names'), 'w') as f:\n",
        "        f.write('\\n'.join(categories))\n",
        "\n",
        "    # obj.data\n",
        "    config_content = f\"\"\"classes = {len(categories)}\n",
        "    train = {os.path.join(base_dir, 'train.txt')}\n",
        "    valid = {os.path.join(base_dir, 'val.txt')}\n",
        "    names = {os.path.join(base_dir, 'obj.names')}\n",
        "    backup = /content/backup\n",
        "    \"\"\"\n",
        "    with open(os.path.join(base_dir, 'obj.data'), 'w') as f:\n",
        "        f.write(config_content)\n",
        "\n",
        "def generate_split_filelists(base_dir: str, splits: list):\n",
        "    \"\"\"Gera os arquivos train.txt e val.txt com caminhos absolutos\"\"\"\n",
        "    for split in splits:\n",
        "        if split == 'test': continue  # Test não tem anotações\n",
        "\n",
        "        img_dir = os.path.join(base_dir, split, 'images')\n",
        "        output_file = os.path.join(base_dir, f'{split}.txt')\n",
        "\n",
        "        with open(output_file, 'w') as f:\n",
        "            for img_name in os.listdir(img_dir):\n",
        "                f.write(f\"{img_dir}/{img_name}\\n\")\n",
        "\n",
        "def process_coco_split(splits: list, categories: list, max_samples_per_split: int = None):\n",
        "    \"\"\"\n",
        "    Processa splits do COCO (train, val, test), filtrando por categorias e convertendo para YOLO.\n",
        "    \"\"\"\n",
        "    # Criar diretório principal\n",
        "    os.makedirs('/content/coco/filtered/', exist_ok=True)\n",
        "\n",
        "    # Criar arquivo de classes\n",
        "    with open('/content/coco/filtered/obj.names', 'w') as f:\n",
        "        for cat in categories:\n",
        "            f.write(cat + '\\n')\n",
        "\n",
        "    for split in splits:\n",
        "        print(f\"\\nProcessando split: {split}\")\n",
        "\n",
        "        # Caminhos das imagens\n",
        "        img_source_dir = f'/content/coco/images/{split}2017'\n",
        "        img_dest_dir = f'/content/coco/filtered/{split}/images'\n",
        "        os.makedirs(img_dest_dir, exist_ok=True)\n",
        "\n",
        "        # Processar apenas train/val (test não tem anotações)\n",
        "        if split != 'test':\n",
        "            # Carregar anotações\n",
        "            coco = COCO(f'/content/coco/annotations/instances_{split}2017.json')\n",
        "            cat_ids = coco.getCatIds(catNms=categories)\n",
        "            img_ids = coco.getImgIds(catIds=cat_ids)\n",
        "\n",
        "            # Limitar amostras se especificado\n",
        "            if max_samples_per_split:\n",
        "                img_ids = img_ids[:max_samples_per_split]\n",
        "\n",
        "            images = coco.loadImgs(img_ids)\n",
        "\n",
        "            # Copiar imagens\n",
        "            for img in images:\n",
        "                src = os.path.join(img_source_dir, img['file_name'])\n",
        "                dst = os.path.join(img_dest_dir, img['file_name'])\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "            # Criar diretório de labels\n",
        "            ann_dest_dir = f'/content/coco/filtered/{split}/labels'\n",
        "            os.makedirs(ann_dest_dir, exist_ok=True)\n",
        "\n",
        "            # Converter anotações para YOLO\n",
        "            for img in images:\n",
        "                ann_ids = coco.getAnnIds(imgIds=img['id'], catIds=cat_ids)\n",
        "                annotations = coco.loadAnns(ann_ids)\n",
        "\n",
        "                label_path = os.path.join(ann_dest_dir, img['file_name'].replace('.jpg', '.txt'))\n",
        "                with open(label_path, 'w') as f:\n",
        "                    for ann in annotations:\n",
        "                        x, y, w, h = ann['bbox']\n",
        "                        img_w, img_h = img['width'], img['height']\n",
        "\n",
        "                        cx = (x + w/2) / img_w\n",
        "                        cy = (y + h/2) / img_h\n",
        "                        nw = w / img_w\n",
        "                        nh = h / img_h\n",
        "\n",
        "                        class_id = categories.index(coco.loadCats(ann['category_id'])[0]['name'])\n",
        "                        f.write(f\"{class_id} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\\n\")\n",
        "\n",
        "        # Processar test (sem anotações)\n",
        "        else:\n",
        "            # Listar todas as imagens do diretório test2017\n",
        "            images = [{'file_name': f} for f in os.listdir(img_source_dir)]\n",
        "            if max_samples_per_split:\n",
        "                images = images[:max_samples_per_split]\n",
        "\n",
        "            # Copiar imagens\n",
        "            for img in images:\n",
        "                src = os.path.join(img_source_dir, img['file_name'])\n",
        "                dst = os.path.join(img_dest_dir, img['file_name'])\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "# Configuração centralizada\n",
        "SPLITS = ['train', 'val', 'test']\n",
        "CATEGORIES = ['boat', 'person']\n",
        "MAX_SAMPLES = 100  # None para usar todos\n",
        "\n",
        "process_coco_split(\n",
        "    splits=SPLITS,\n",
        "    categories=CATEGORIES,\n",
        "    max_samples_per_split=MAX_SAMPLES\n",
        ")"
      ],
      "metadata": {
        "id": "5KkwWlCNdKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos diretórios de treino e validação"
      ],
      "metadata": {
        "id": "esURIogweBx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifique se existem e contêm caminhos das imagens\n",
        "!ls /content/coco/filtered/train.txt /content/coco/filtered/val.txt\n",
        "\n",
        "# Exemplo do conteúdo de train.txt (primeiras 2 linhas)\n",
        "!head -n 2 /content/coco/filtered/train.txt"
      ],
      "metadata": {
        "id": "Od-tqcwkx0Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/coco/filtered -L 2"
      ],
      "metadata": {
        "id": "zPF2dxzax4Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação de Integridade"
      ],
      "metadata": {
        "id": "AZn-Nfw5eIIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_dataset(base_dir: str, splits: list):\n",
        "    \"\"\"Valida se número de imagens e labels corresponde\"\"\"\n",
        "    for split in splits:\n",
        "        img_dir = os.path.join(base_dir, split, 'images')\n",
        "        label_dir = os.path.join(base_dir, split, 'labels'))\n",
        "\n",
        "        num_images = len(os.listdir(img_dir))\n",
        "        num_labels = len(os.listdir(label_dir)) if split != 'test' else 0\n",
        "\n",
        "        print(f\"{split}: {num_images} imagens, {num_labels} labels\")\n",
        "        if split != 'test' and num_images != num_labels:\n",
        "            raise ValueError(\"Inconsistência entre imagens e labels!\")"
      ],
      "metadata": {
        "id": "Lhr0hXuuYAEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Controle de Versão dos Arquivos Gerados"
      ],
      "metadata": {
        "id": "D308fR_6ePyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset_version(base_dir: str):\n",
        "    \"\"\"Salva metadados da versão do dataset\"\"\"\n",
        "    version_info = {\n",
        "        'created_at': datetime.now().isoformat(),\n",
        "        'categories': CATEGORIES,\n",
        "        'splits': SPLITS,\n",
        "        'num_samples': {split: len(os.listdir(os.path.join(base_dir, split, 'images')))\n",
        "                       for split in SPLITS}\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(base_dir, 'version.json'), 'w') as f:\n",
        "        json.dump(version_info, f, indent=2)"
      ],
      "metadata": {
        "id": "eyDr4J-5YEuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documentação"
      ],
      "metadata": {
        "id": "3TIfN1W0eTt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_documentation(base_dir: str):\n",
        "    \"\"\"Cria arquivo README com informações do dataset\"\"\"\n",
        "    readme_content = f\"\"\"# COCO Filtered Dataset\n",
        "\n",
        "    ## Categories\n",
        "    {', '.join(CATEGORIES)}\n",
        "\n",
        "    ## Splits\n",
        "    {', '.join(SPLITS)}\n",
        "\n",
        "    ## Statistics\n",
        "    \"\"\"\n",
        "    for split in SPLITS:\n",
        "        num_images = len(os.listdir(os.path.join(base_dir, split, 'images')))\n",
        "        readme_content += f\"\\n- {split}: {num_images} images\"\n",
        "\n",
        "    with open(os.path.join(base_dir, 'README.md'), 'w') as f:\n",
        "        f.write(readme_content)"
      ],
      "metadata": {
        "id": "XoMftU-6YHUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adição dos pesos para treino"
      ],
      "metadata": {
        "id": "ggyyvb7MeXdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "id": "WdkVSZXUiGNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação do diretório onde os pesos foram salvos"
      ],
      "metadata": {
        "id": "2NO48XYGeZ4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!which yolov3.weights"
      ],
      "metadata": {
        "id": "C200_GyniY6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos nomes"
      ],
      "metadata": {
        "id": "hkaX4yUpehqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/coco/filtered/obj.names"
      ],
      "metadata": {
        "id": "8_zl8w5oxCTq",
        "outputId": "0e66b62b-76c0-4c52-a059-02aaa18538e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "boat\n",
            "person\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos dados"
      ],
      "metadata": {
        "id": "-RxO0BmAemBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/coco/filtered/obj.data"
      ],
      "metadata": {
        "id": "cYBVcPx2xk46",
        "outputId": "07dd77d3-f5a0-4ff4-cea3-3d87fb3a4f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes = 2\n",
            "train = /content/coco/filtered/train.txt\n",
            "valid = /content/coco/filtered/val.txt\n",
            "names = /content/coco/filtered/obj.names\n",
            "backup = /content/backup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração dos arquvios para treino"
      ],
      "metadata": {
        "id": "R7o203YSepFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria cópia do cfg original\n",
        "!cp cfg/yolov3.cfg cfg/yolov3_custom.cfg\n",
        "\n",
        "# Aplica modificações\n",
        "!sed -i 's/batch=1/batch=64/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/subdivisions=1/subdivisions=16/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/max_batches = 500200/max_batches = 6000/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/classes=80/classes=2/' cfg/yolov3_custom.cfg\n",
        "!sed -i 's/filters=255/filters=21/' cfg/yolov3_custom.cfg"
      ],
      "metadata": {
        "id": "J6gD6lItiq-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução dos testes"
      ],
      "metadata": {
        "id": "MBvNWFjnet6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector train /content/coco/filtered/obj.data cfg/yolov3_custom.cfg yolov3.weights -dont_show -map"
      ],
      "metadata": {
        "id": "cG7Rr9mHwzUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/coco/filtered/train -L 2"
      ],
      "metadata": {
        "id": "Zn_gjiEA0FIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}