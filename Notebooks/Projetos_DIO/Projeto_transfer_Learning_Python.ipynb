{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Projeto de Transfer Learning em Python\n",
        "O projeto consiste em aplicar o método de Transfer Learning em uma rede de Deep Learning na linguagem Python no ambiente COLAB.  "
      ],
      "metadata": {
        "id": "tYFUPrSkIvS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WID2D7_BOBu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" -O \"/home/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/home/cats-and-dogs.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/home')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyM2_CJUI5ZP",
        "outputId": "8d04252b-b4df-403e-cbcd-eac75947b91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-09 22:42:25--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.210.240.213, 2600:1408:9000:6ac::317f, 2600:1408:9000:68a::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.210.240.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‘/home/cats-and-dogs.zip’\n",
            "\n",
            "/home/cats-and-dogs 100%[===================>] 786.67M  79.4MB/s    in 9.4s    \n",
            "\n",
            "2025-02-09 22:42:35 (83.4 MB/s) - ‘/home/cats-and-dogs.zip’ saved [824887076/824887076]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/home/PetImages/Cat/')))\n",
        "print(len(os.listdir('/home/PetImages/Dog/')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og85IrhJKuMJ",
        "outputId": "bfbe651a-2190-4f33-895f-46349b23e4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12501\n",
            "12501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir('/home/cats-v-dogs')\n",
        "  os.mkdir('/home/cats-v-dogs/training')\n",
        "  os.mkdir('/home/cats-v-dogs/testing')\n",
        "  os.mkdir('/home/cats-v-dogs/training/cats')\n",
        "  os.mkdir('/home/cats-v-dogs/training/dogs')\n",
        "  os.mkdir('/home/cats-v-dogs/testing/cats')\n",
        "  os.mkdir('/home/cats-v-dogs/testing/dogs')\n",
        "except OSError as e:\n",
        "  print(\"Error creating director: {e}\")\n",
        "  pass"
      ],
      "metadata": {
        "id": "Sr_VqR2IK9Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição da Rede Neural\n"
      ],
      "metadata": {
        "id": "gU_X6nh8OjYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "  files = []\n",
        "  for filename in os.listdir(SOURCE):\n",
        "    file = SOURCE + filename\n",
        "    if os.path.getsize(file) > 0:\n",
        "        files.append(filename)\n",
        "    else:\n",
        "        print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "  training_length = int(len(files) * SPLIT_SIZE)\n",
        "  testing_length = int(len(files) - training_length)\n",
        "  shuffled_set = random.sample(files, len(files))\n",
        "  training_set = shuffled_set[0:training_length]\n",
        "  testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "  for filename in training_set:\n",
        "    this_file = SOURCE + filename\n",
        "    destination = TRAINING + filename\n",
        "    copyfile(this_file, destination)\n",
        "\n",
        "  for filename in testing_set:\n",
        "    this_file = SOURCE + filename\n",
        "    destination = TESTING + filename\n",
        "    copyfile(this_file, destination)\n",
        "\n",
        "CAT_SOURCE_DIR = \"/home/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/home/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/home/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/home/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/home/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/home/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RESUJsqMQPK",
        "outputId": "f11633bd-46a1-4e8b-ec01-0de18a22f290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/home/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/home/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/home/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/home/cats-v-dogs/testing/dogs/')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwMXtQE0MleU",
        "outputId": "3af447e5-778c-45e1-dc44-22accdcb8b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g45u6OuRPVWE",
        "outputId": "d8383799-a98b-44ac-f61e-bcd7a1633bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = \"/home/cats-v-dogs/training\"\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "VALIDATION_DIR = \"/home/cats-v-dogs/testing\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=100,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-GlhuQqV_Rf",
        "outputId": "c5031f73-b1c4-4e4e-e943-bb29a7bf9806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22499 images belonging to 2 classes.\n",
            "Found 2499 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=15, steps_per_epoch=20, validation_data=validation_generator, validation_steps=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxcxKRpyWpNP",
        "outputId": "208d1f9e-32a7-4b14-9728-03667425c4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - acc: 0.5621 - loss: 0.6907 - val_acc: 0.4983 - val_loss: 0.7286\n",
            "Epoch 2/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.5415 - loss: 0.6963 - val_acc: 0.5117 - val_loss: 0.6938\n",
            "Epoch 3/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.5665 - loss: 0.6948 - val_acc: 0.5717 - val_loss: 0.6677\n",
            "Epoch 4/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.6029 - loss: 0.6672 - val_acc: 0.6400 - val_loss: 0.6516\n",
            "Epoch 5/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - acc: 0.6533 - loss: 0.6405 - val_acc: 0.6400 - val_loss: 0.6436\n",
            "Epoch 6/15\n",
            "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2s/step - acc: 0.6766 - loss: 0.6282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.6721 - loss: 0.6314 - val_acc: 0.6883 - val_loss: 0.6086\n",
            "Epoch 7/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3s/step - acc: 0.6715 - loss: 0.6237 - val_acc: 0.6767 - val_loss: 0.6178\n",
            "Epoch 8/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.6399 - loss: 0.6279 - val_acc: 0.7033 - val_loss: 0.6169\n",
            "Epoch 9/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.7064 - loss: 0.5955 - val_acc: 0.6983 - val_loss: 0.5858\n",
            "Epoch 10/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.6856 - loss: 0.5799 - val_acc: 0.7133 - val_loss: 0.5706\n",
            "Epoch 11/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.6830 - loss: 0.5871 - val_acc: 0.7033 - val_loss: 0.5584\n",
            "Epoch 12/15\n",
            "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 2s/step - acc: 0.7509 - loss: 0.5217"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 954ms/step - acc: 0.7562 - loss: 0.5221 - val_acc: 0.7050 - val_loss: 0.5629\n",
            "Epoch 13/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 3s/step - acc: 0.7010 - loss: 0.5802 - val_acc: 0.7350 - val_loss: 0.5296\n",
            "Epoch 14/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.7065 - loss: 0.5416 - val_acc: 0.6817 - val_loss: 0.5693\n",
            "Epoch 15/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - acc: 0.7167 - loss: 0.5565 - val_acc: 0.7483 - val_loss: 0.5125\n"
          ]
        }
      ]
    }
  ]
}